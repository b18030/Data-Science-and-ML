{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scrapy is an open source Python framework for crawling websites and extracting data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://2.bp.blogspot.com/-oeOzu13C26U/V1_2uXbFE4I/AAAAAAAAALI/2RmiWjCb--YUVO6MAg3pG5eIOISFkVwBgCLcB/s1600/custom-web-scraping-624x301.png)\n",
    "Any web page you see on the internet can be crawled for information and anything visible on a web page can be extracted.\n",
    "Every web page has its own structure and web elements that because of which you need to write your web crawlers/spiders according to the web page being extracted.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'scrapyproject', using template directory 'c:\\users\\lmd\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    C:\\Users\\lmd\\Documents\\Data-Science-and-ML\\scrapyproject\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd scrapyproject\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject scrapyproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class BrickSetSpider(scrapy.Spider):\n",
    "    name = \"brickset_spider\"\n",
    "    start_urls = ['http://brickset.com/sets/year-2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import scrapy so that we can use the classes that the package provides.\n",
    "\n",
    "- Next, we take the Spider class provided by Scrapy and make a subclass out of it called BrickSetSpider. Think of a subclass as a more specialized form of its parent class.\n",
    "- The Spider subclass has methods and behaviors that define how to follow URLs and extract data from the pages it finds, but it doesn't know where to look or what data to look for. By subclassing it, we can give it that information.\n",
    "- Then we give the spider the name brickset_spider.\n",
    "- then we give our scraper a single URL to start from: http://brickset.com/sets/year-2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http:', '', 'quotes.toscrape.com', 'page', '1', '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'http://quotes.toscrape.com/page/1/'.split('/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__parse(self, response)__: This function will be called whenever a URL is crawled successfully. It is also called the callback function. The response (used in Scrapy shell) returned as a result of crawling is passed in this function, and you write the extraction code inside it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
