{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this post, we are going to learn about implementing linear regression on Boston Housing dataset using scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset\n",
    "   <img src=\"boston.jpeg\" alt=\"drawing\" style=\"width:490px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Boston Housing Dataset consists of price of houses in various places in Boston\n",
    "- There are 506 samples and 13 feature variables in this dataset. The __objective__ is to __predict the value of prices of the house__  using the given features.\n",
    "- __We can also access this data from the scikit-learn library__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Steps--__\n",
    "- The data should be partitioned into __training and validation sets__ because we need two sets of data: one to build the model that depicts the relationship between the predictor variables and the predicted variable, and another to validate the model‚Äüs predictive accuracy.\n",
    "- The training data set is used to build the model. The algorithm ‚Äûdiscovers‚Äü the\n",
    "model using this data set.\n",
    "- The validation data is used to 'validate' the model. In this process, the model (built using the training data set) is used to make predictions with thevalidation data - data that were not used to fit the model. In this way we getan unbiased estimate of how well the model performs. We compute measures of 'error', which reflect the prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Untitled-drawing-1-11.png)\n",
    "<br>\n",
    "__The dependent variable is MEDV - Median value of owner-occupied homes__ in $1000's "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let‚Äôs get started.\n",
    "\n",
    "#### First, we will import the required libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boston_dataset) - U can see the data set\n",
    "X=boston_dataset.data\n",
    "Y=boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(boston_dataset.keys())\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data: contains the information for various houses\n",
    "- target: prices of the house\n",
    "- feature_names: names of the features\n",
    "- DESCR: describes the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prices of the house indicated by the variable MEDV is our target variable and the remaining are the feature variables based on which we will predict the value of a house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)#Its a Random Split of data.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.37599200e-01  5.67986712e-02  5.84764486e-03  3.98380452e+00\n",
      " -1.33584744e+01  3.94063974e+00 -7.78726190e-03 -1.63280336e+00\n",
      "  2.94634607e-01 -1.07830014e-02 -7.18869283e-01  1.08037103e-02\n",
      " -6.29369660e-01]\n",
      "30.44412535491947\n"
     ]
    }
   ],
   "source": [
    "# CREATE OBJECT\n",
    "lr=LinearRegression(normalize=True)\n",
    "# 2. Training\n",
    "lr.fit(X_train,Y_train)\n",
    "#3. Output parameters\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Regression:\n",
    "#### model.score() : for classification or regression problems, most (all?) estimators implement a score method. Scores are between 0 and 1, with a larger score indicating a better fit\n",
    "> Once you have your model fitted, you can get the results to check whether the model works    satisfactorily and interpret it. You can obtain the __coefficient of determination (ùëÖ¬≤)__ with .score() called on model<br>\n",
    "> __The R^2 (or R Squared) metric provides an indication of the goodness of fit of a set of predictions to the actual values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score 0.7498\n",
      "Testing Score 0.6379\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Score %.4f\"%lr.score(X_train,Y_train))\n",
    "print(\"Testing Score %.4f\"%lr.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The independent features are called the independent variables, inputs, or predictors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting vs. Underfitting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://cdn-images-1.medium.com/max/1000/1*6vPGzBNppqMHllg1o_se8Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Overfitting__: too much reliance on the training data\n",
    "- __Underfitting__: a failure to learn the relationships in the training data4\n",
    "- __Overfitting and underfitting__ cause poor generalization on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem of Overfitting vs Underfitting finally appears when we talk about the polynomial degree.\n",
    "### An underfit model will be less flexible and cannot account for the data\n",
    "-  A model that is underfit will have __high training and high testing error__  while an overfit model will have __extremely low training error but a high testing error.__\n",
    "- Both overfitting and underfitting lead to poor predictions on new data sets\n",
    "- Overfitting is often a result of an __excessively complicated model__, and it can be prevented by fitting multiple models and using validation or cross-validation to compare their predictive accuracies on test data.\n",
    "#### Overfitting refers to a model that models the training data too well.\n",
    "#### Underfitting refers to a model that can neither model the training data nor generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
